{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設個picture大小及data路徑\n",
    "pic_size = 128\n",
    "image_path = './dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1616 blank images\n",
      "1752 fist images\n",
      "2019 five images\n",
      "1675 ok images\n",
      "1641 thumbsdown images\n",
      "1618 thumbsup images\n"
     ]
    }
   ],
   "source": [
    "# 印出dataset中各類有幾張image\n",
    "for image_count in os.listdir(image_path):\n",
    "    print(str(len(os.listdir(image_path + image_count))) + \" \" + image_count + \" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_image_file:  10321\n"
     ]
    }
   ],
   "source": [
    "# 記錄總共有幾張image\n",
    "file_count = 0\n",
    "for floderName in os.listdir(image_path):\n",
    "    for filename in os.listdir(image_path + floderName):\n",
    "        file_count +=1\n",
    "print('all_image_file: ',file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立空的np_array (待會填label用)\n",
    "label_default = np.zeros(shape=[file_count])\n",
    "img_default = np.zeros(shape=[file_count,pic_size,pic_size])\n",
    "file_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 給各個floder中的image上label\n",
    "for floderName in os.listdir(image_path):\n",
    "    for filename in os.listdir(image_path + floderName):        \n",
    "            \n",
    "        temp = cv2.imread(image_path + floderName + \"/\" + filename,0)\n",
    "        temp = cv2.resize(temp, (pic_size,pic_size))\n",
    "        img_default[file_count] = temp\n",
    "        \n",
    "        if floderName == 'blank':\n",
    "            label_default[file_count] = 0\n",
    "        elif floderName == 'fist':\n",
    "            label_default[file_count] = 1\n",
    "        elif floderName == 'five':\n",
    "            label_default[file_count] = 2\n",
    "        elif floderName == 'ok':\n",
    "            label_default[file_count] = 3\n",
    "        elif floderName == 'thumbsdown':\n",
    "            label_default[file_count] = 4\n",
    "        elif floderName == 'thumbsup':\n",
    "            label_default[file_count] = 5          \n",
    "            \n",
    "        file_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_onehot[0]:[1. 0. 0. 0. 0. 0.],label_dim:2,shape:(10321, 6)\n"
     ]
    }
   ],
   "source": [
    "# reshape成丟進model input的dimension\n",
    "img_default = img_default.reshape(file_count,pic_size,pic_size,1)\n",
    "img_default.shape\n",
    "\n",
    "label_onehot=np_utils.to_categorical(label_default) # 做onehot encoding\n",
    "print('label_onehot[0]:{},label_dim:{},shape:{}'.format(label_onehot[0],label_onehot.ndim,label_onehot.shape)) \n",
    "# Label(Encoding結果 , 維度, shape)\n",
    "img_default = img_default / 255.0 \n",
    "# 做 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:(8256, 128, 128, 1)\n",
      " y_train.shape:(8256, 6)\n",
      " x_test.shape:(2065, 128, 128, 1)\n",
      " y_test.shape:(2065, 6)\n"
     ]
    }
   ],
   "source": [
    "random_seed  = 3 # 隨機分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_default, label_onehot, test_size = 0.2, random_state=random_seed) # 切分訓練及測試集\n",
    "print(' x_train.shape:{}\\n y_train.shape:{}\\n x_test.shape:{}\\n y_test.shape:{}'.format(x_train.shape, y_train.shape, x_test.shape, y_test.shape)) \n",
    "#(train_img, train_label, test_img, test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 3,706,406\n",
      "Trainable params: 3,706,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "model.add(Conv2D(64, 3, activation='relu', input_shape=(pic_size,pic_size,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# second conv layer\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten and put a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) # fully connected\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax layer\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "optimiser = Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將訓練好的model儲存成json及h5檔\n",
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_trained.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "model.save(\"model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
